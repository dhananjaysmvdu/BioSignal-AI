{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca886bf6",
   "metadata": {},
   "source": [
    "# BioSignal-X Baseline Benchmarks\n",
    "This notebook compares EfficientNet-B0 + metadata fusion vs. ViT-based fusion on ISIC/HAM10000 templates.\n",
    "Metrics: AUC, sensitivity, specificity, Brier score, ECE, and Grad-CAM visualization. Outputs results to `results/benchmark_metrics.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, math, json, random, time, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score, brier_score_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "import sys\n",
    "sys.path.append(str(Path('src').resolve()))\n",
    "from data_loader import build_dataset\n",
    "from models.biosignal_model import BioSignalModel\n",
    "from utils.gradcam import GradCAM\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "RESULTS_DIR = Path('results'); RESULTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8869cb6a",
   "metadata": {},
   "source": [
    "### Data Templates (ISIC/HAM10000)\n",
    "Update the paths below to point to your local ISIC/HAM10000 datasets. For quick smoke tests, the synthetic sample dataset is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect dataset and prepare SkinDataset\n",
    "DATA_ROOT = Path('data')\n",
    "\n",
    "def detect_dataset():\n",
    "    candidates = [\n",
    "        ('isic2019', DATA_ROOT / 'isic2019'),\n",
    "        ('isic2018', DATA_ROOT / 'isic2018'),\n",
    "        ('ham10000', DATA_ROOT / 'ham10000'),\n",
    "        ('sample', DATA_ROOT / 'synthetic_benchmark'),\n",
    "    ]\n",
    "    for name, root in candidates:\n",
    "        meta = root / 'metadata.csv'\n",
    "        if meta.exists() or root.exists():\n",
    "            return name, root\n",
    "    # Default to sample\n",
    "    return 'sample', DATA_ROOT / 'synthetic_benchmark'\n",
    "\n",
    "dataset_key, root = detect_dataset()\n",
    "print('Using dataset:', dataset_key, 'at', root)\n",
    "\n",
    "# Build dataset (creates sample or indexes if needed)\n",
    "ds = build_dataset(root, dataset_key)\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "indices = np.arange(len(ds))\n",
    "np.random.seed(42); np.random.shuffle(indices)\n",
    "split = int(0.8*len(ds))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "train_loader = DataLoader(Subset(ds, train_idx), batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(Subset(ds, val_idx), batch_size=32, shuffle=False, num_workers=0)\n",
    "n_classes = 2\n",
    "n_meta = ds[0][1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef656ac4",
   "metadata": {},
   "source": [
    "### Models: EfficientNet-B0 + metadata fusion vs. ViT-based fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet-based model from project\n",
    "eff_model = BioSignalModel(num_classes=n_classes, metadata_dim=n_meta).to(DEVICE)\n",
    "\n",
    "# ViT-based fusion baseline using timm\n",
    "import timm\n",
    "class ViTFusion(nn.Module):\n",
    "    def __init__(self, num_classes, metadata_dim, vit_name='vit_base_patch16_224'):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model(vit_name, pretrained=False, num_classes=0)\n",
    "        vis_dim = self.vit.num_features\n",
    "        self.meta = nn.Sequential(nn.Linear(metadata_dim, 64), nn.ReLU(), nn.Dropout(0.1), nn.Linear(64, 64), nn.ReLU())\n",
    "        self.head = nn.Sequential(nn.Linear(vis_dim+64, 128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, num_classes))\n",
    "    def forward(self, x, m):\n",
    "        v = self.vit(x)\n",
    "        u = self.meta(m)\n",
    "        return self.head(torch.cat([v,u], dim=1))\n",
    "\n",
    "vit_model = ViTFusion(n_classes, n_meta).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b5db6",
   "metadata": {},
   "source": [
    "### Training/Evaluation Utilities and Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15946f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ece_score(probs, labels, n_bins=10):\n",
    "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
    "    idx = np.digitize(probs, bins) - 1\n",
    "    ece = 0.0\n",
    "    for b in range(n_bins):\n",
    "        mask = idx == b\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        acc = (labels[mask] == (probs[mask] >= 0.5)).mean()\n",
    "        conf = probs[mask].mean()\n",
    "        ece += (np.sum(mask)/len(probs)) * abs(acc - conf)\n",
    "    return float(ece)\n",
    "\n",
    "def fairness_groups(raw_df: pd.DataFrame):\n",
    "    groups = {}\n",
    "    if 'gender' in raw_df.columns:\n",
    "        for g in raw_df['gender'].dropna().unique():\n",
    "            groups[f'gender:{g}'] = raw_df[raw_df['gender']==g].index.tolist()\n",
    "    if 'age' in raw_df.columns:\n",
    "        age_bins = pd.cut(raw_df['age'], bins=[0,30,50,70,200], labels=['0-30','31-50','51-70','71+'])\n",
    "        for ab in age_bins.unique():\n",
    "            groups[f'age:{ab}'] = raw_df[age_bins==ab].index.tolist()\n",
    "    if 'skin_type' in raw_df.columns:\n",
    "        for st in raw_df['skin_type'].dropna().unique():\n",
    "            groups[f'skin_type:{st}'] = raw_df[raw_df['skin_type']==st].index.tolist()\n",
    "    return groups\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device=DEVICE, raw_df: pd.DataFrame | None = None, subset_indices=None):\n",
    "    model.eval()\n",
    "    y_true, y_prob = [], []\n",
    "    all_indices = []\n",
    "    for i, batch in enumerate(loader):\n",
    "        imgs, meta, labels = batch[0], batch[1], batch[2] if len(batch)==3 else batch[2]\n",
    "        imgs, meta, labels = imgs.to(device), meta.to(device), labels.to(device)\n",
    "        logits, probs_full = model(imgs, meta)\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "        y_true.append(labels.detach().cpu().numpy())\n",
    "        y_prob.append(probs.detach().cpu().numpy())\n",
    "        start = i * loader.batch_size\n",
    "        for k in range(imgs.size(0)):\n",
    "            all_indices.append(start + k)\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_prob = np.concatenate(y_prob)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sens = tp / (tp + fn + 1e-8)\n",
    "    spec = tn / (tn + fp + 1e-8)\n",
    "    brier = brier_score_loss(y_true, y_prob)\n",
    "    ece = ece_score(y_prob, y_true)\n",
    "    metrics = {\n",
    "        'auc': float(auc), 'sensitivity': float(sens), 'specificity': float(spec),\n",
    "        'brier': float(brier), 'ece': float(ece)\n",
    "    }\n",
    "    if raw_df is not None:\n",
    "        fg = fairness_groups(raw_df)\n",
    "        fairness = {}\n",
    "        for name, idxs in fg.items():\n",
    "            local = [i for i in idxs if i < len(y_true)]\n",
    "            if len(local) < 5:\n",
    "                continue\n",
    "            yt = y_true[local]\n",
    "            yp = y_prob[local]\n",
    "            try:\n",
    "                g_auc = roc_auc_score(yt, yp)\n",
    "            except Exception:\n",
    "                g_auc = float('nan')\n",
    "            ypp = (yp >= 0.5).astype(int)\n",
    "            tn2, fp2, fn2, tp2 = confusion_matrix(yt, ypp).ravel() if len(set(yt))>1 else (0,0,0,0)\n",
    "            fairness[name] = {\n",
    "                'auc': float(g_auc),\n",
    "                'sens': float(tp2/(tp2+fn2+1e-8) if (tp2+fn2)>0 else float('nan')),\n",
    "                'spec': float(tn2/(tn2+fp2+1e-8) if (tn2+fp2)>0 else float('nan'))\n",
    "            }\n",
    "        metrics['fairness'] = fairness\n",
    "    return metrics\n",
    "\n",
    "def save_metrics(name, metrics, path=RESULTS_DIR/\"benchmark_metrics.csv\"):\n",
    "    flat = {'model': name, **{k:v for k,v in metrics.items() if k!='fairness'}}\n",
    "    if Path(path).exists():\n",
    "        pd.DataFrame([flat]).to_csv(path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        pd.DataFrame([flat]).to_csv(path, index=False)\n",
    "    # fairness dump separate JSON\n",
    "    if 'fairness' in metrics:\n",
    "        (RESULTS_DIR/\"fairness\").mkdir(exist_ok=True)\n",
    "        with open(RESULTS_DIR/\"fairness\"/f\"{name}_fairness.json\", 'w', encoding='utf-8') as fh:\n",
    "            json.dump(metrics['fairness'], fh, indent=2)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d68176",
   "metadata": {},
   "source": [
    "### Quick Training (1 epoch) and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77fc47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, device=DEVICE, lr=1e-3):\n",
    "    model.train()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for imgs, meta, labels in loader:\n",
    "        imgs, meta, labels = imgs.to(device), meta.to(device, dtype=torch.float), labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        logits, _ = model(imgs, meta)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward(); opt.step()\n",
    "\n",
    "# Train tiny epoch and evaluate both models\n",
    "eff_model = BioSignalModel(metadata_dim=n_meta).to(DEVICE)\n",
    "train_one_epoch(eff_model, train_loader)\n",
    "eff_metrics = evaluate(eff_model, val_loader, device=DEVICE, raw_df=getattr(ds, 'frame', None))\n",
    "save_metrics('efficientnet_b0_fusion', eff_metrics)\n",
    "print('EfficientNet metrics:', eff_metrics)\n",
    "\n",
    "import timm\n",
    "class ViTFusion(nn.Module):\n",
    "    def __init__(self, num_classes, metadata_dim, vit_name='vit_base_patch16_224'):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model(vit_name, pretrained=False, num_classes=0)\n",
    "        vis_dim = self.vit.num_features\n",
    "        self.meta = nn.Sequential(nn.Linear(metadata_dim, 64), nn.ReLU(), nn.Dropout(0.1), nn.Linear(64, 64), nn.ReLU())\n",
    "        self.head = nn.Sequential(nn.Linear(vis_dim+64, 128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, num_classes))\n",
    "    def forward(self, x, m):\n",
    "        v = self.vit(x)\n",
    "        u = self.meta(m)\n",
    "        return self.head(torch.cat([v,u], dim=1))\n",
    "\n",
    "vit_model = ViTFusion(n_classes, n_meta).to(DEVICE)\n",
    "train_one_epoch(vit_model, train_loader)\n",
    "vit_logits = lambda imgs, metas: vit_model(imgs, metas)\n",
    "vit_metrics = evaluate(vit_model, val_loader, device=DEVICE, raw_df=getattr(ds, 'frame', None))\n",
    "save_metrics('vit_base_patch16_fusion', vit_metrics)\n",
    "print('ViT metrics:', vit_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27aeed",
   "metadata": {},
   "source": [
    "### Grad-CAM Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grad-CAM on a single validation sample (EfficientNet)\n",
    "batch = next(iter(val_loader))\n",
    "img, meta, lbl = batch[0][0:1].to(DEVICE), batch[1][0:1].to(DEVICE, dtype=torch.float), batch[2][0:1]\n",
    "\n",
    "eff_model.eval()\n",
    "cam = GradCAM(eff_model)\n",
    "cam_map = cam(img, meta)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(cam_map, cmap='jet')\n",
    "plt.title('Grad-CAM (EfficientNet Fusion)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter-site performance variance analysis\n",
    "import json, csv\n",
    "from pathlib import Path as _P\n",
    "sites_col = None\n",
    "raw_df = getattr(ds, 'frame', None)\n",
    "if raw_df is not None:\n",
    "    # Identify site columns (binary flags) or single 'site' column\n",
    "    site_flag_cols = [c for c in raw_df.columns if c.lower().startswith('site_')]\n",
    "    if site_flag_cols:\n",
    "        site_groups = {}\n",
    "        for c in site_flag_cols:\n",
    "            members = raw_df[raw_df[c]==1].index.tolist()\n",
    "            if members:\n",
    "                site_groups[c] = members\n",
    "    elif 'site' in raw_df.columns:\n",
    "        site_groups = {f\"site:{s}\": raw_df[raw_df['site']==s].index.tolist() for s in raw_df['site'].unique()}\n",
    "    else:\n",
    "        site_groups = {}\n",
    "    inter_rows = []\n",
    "    for site_name, idxs in site_groups.items():\n",
    "        if len(idxs) < 5:\n",
    "            continue\n",
    "        subset = Subset(ds, idxs)\n",
    "        loader_site = DataLoader(subset, batch_size=32, shuffle=False, num_workers=0)\n",
    "        m_eff = evaluate(eff_model, loader_site, device=DEVICE, raw_df=raw_df)\n",
    "        inter_rows.append({'site': site_name, 'auc': m_eff['auc'], 'sens': m_eff['sensitivity'], 'spec': m_eff['specificity']})\n",
    "    if inter_rows:\n",
    "        import pandas as _pd\n",
    "        inter_df = _pd.DataFrame(inter_rows)\n",
    "        (_P('results')/ 'plots').mkdir(exist_ok=True)\n",
    "        inter_df.to_csv('results/inter_site_variability.csv', index=False)\n",
    "        # Boxplot\n",
    "        plt.figure(figsize=(6,4))\n",
    "        for metric in ['auc','sens','spec']:\n",
    "            plt.boxplot(inter_df[metric].dropna(), positions=[{'auc':1,'sens':2,'spec':3}[metric]], widths=0.6)\n",
    "        plt.xticks([1,2,3], ['AUC','Sensitivity','Specificity'])\n",
    "        plt.title('Inter-Site Performance Variance')\n",
    "        plt.savefig('results/plots/inter_site_variance.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print('Inter-site variance artifacts written.')\n",
    "else:\n",
    "    print('No raw dataframe available for inter-site variance analysis.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
